{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf500
\cocoascreenfonts1{\fonttbl\f0\fnil\fcharset0 OpenSans;\f1\fnil\fcharset0 OpenSans-Bold;}
{\colortbl;\red255\green255\blue255;\red26\green0\blue255;\red249\green249\blue249;\red42\green44\blue46;
\red42\green44\blue46;\red249\green249\blue249;\red34\green92\blue192;\red114\green44\blue253;\red74\green0\blue230;
\red34\green92\blue192;}
{\*\expandedcolortbl;;\cspthree\c13799\c8948\c96218;\cssrgb\c98039\c98039\c98039;\cssrgb\c21569\c22745\c23529;
\cssrgb\c21569\c22745\c23529;\cssrgb\c98039\c98039\c98039;\cssrgb\c16471\c45098\c80000;\cssrgb\c52799\c30710\c99498;\cssrgb\c36820\c18688\c92265;
\cssrgb\c16471\c45098\c80000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\vieww33400\viewh21000\viewkind0
\deftab720
\pard\pardeftab720\sl420\sa400\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
STEP 1 = Exploring Data Data Sources and Use Cases\cf2 \cb3 \
\pard\pardeftab720\sl400\sa400\partightenfactor0
\cf5 \cb6 \outl0\strokewidth0 \strokec5 Open data is a very big movement and we want to encourage you to use open data for your project. But you are of course also allowed to use data from another source, including your company\'92s data. Finally, you are also allowed (although we don\'92t really encourage you to do so) to create a test data generator / simulator in case you want to support an interesting use case but can\'92t get hold of relevant data.\
Please take a moment and search for an open data set of your interest. Have a brief look at the data and decide on the use-case you want to implement.\
Here are some examples of open data sets\
{\field{\*\fldinst{HYPERLINK "https://opendata.cityofnewyork.us/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://opendata.cityofnewyork.us/}}\
{\field{\*\fldinst{HYPERLINK "https://www.kaggle.com/datasets"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://www.kaggle.com/datasets}}\
And there a very nice and maintained list\
{\field{\*\fldinst{HYPERLINK "https://github.com/awesomedata/awesome-public-datasets"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://github.com/awesomedata/awesome-public-datasets}}\
Here are some examples of Use-Cases categories\
Examples from the IBM Call for Code Challenge\
- Use AI and bots to improve real-time communications with natural language processing =>\'a0{\field{\*\fldinst{HYPERLINK "https://developer.ibm.com/callforcode/resources/translate/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://developer.ibm.com/callforcode/resources/translate/}}\
- Understand, analyze, and predict health and nutrition needs to improve services with data science =>\'a0{\field{\*\fldinst{HYPERLINK "https://developer.ibm.com/callforcode/resources/healthcare/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://developer.ibm.com/callforcode/resources/healthcare/}}\
- Improve logistics based on traffic and weather activity to predict the number of people affected =>\'a0{\field{\*\fldinst{HYPERLINK "https://developer.ibm.com/callforcode/resources/traffic-and-weather/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://developer.ibm.com/callforcode/resources/traffic-and-weather/}}\
- Collect and analyze device sensor data to take corrective or preventative action automatically =>\'a0{\field{\*\fldinst{HYPERLINK "https://developer.ibm.com/callforcode/resources/preventative-action/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://developer.ibm.com/callforcode/resources/preventative-action/}}\
- Use machine learning, deep learning, and visual recognition to improve critical processes =>\'a0{\field{\*\fldinst{HYPERLINK "https://developer.ibm.com/callforcode/resources/visual-recognition/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://developer.ibm.com/callforcode/resources/visual-recognition/}}\
More generic examples:\
- Predicting the Best Retail Location\
- Detecting insurance fraud\
- Predicting crowd movement on public events\
- Predict heart rate based on activity\
- Optimize irrigation based on moisture sensor values and weather forecast\
- Predict production machine failure based on vibration sensor data\
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 \cb3 \outl0\strokewidth0 j\cf5 \cb6 \outl0\strokewidth0 \strokec5 Once you\'92ve come up with an interesting use-case and data set please move on the next week.\
\pard\pardeftab720\sl400\sa400\partightenfactor0
\cf5 Once you've identified a Use Case and Data Set it is time to get familiar with data. In the process model this task is called Initial Data Exploration. Please take a minute or two to (re)visit the following lecture\
\pard\pardeftab720\sl400\sa400\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.coursera.org/learn/data-science-methodology"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 https://www.coursera.org/learn/data-science-methodology}}\'a0Module 2 - Data Understanding\
Please also revisit\'a0{\field{\*\fldinst{HYPERLINK "http://coursera.org/learn/ds/"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 http://coursera.org/learn/ds/}}\'a0Module 3 - Mathematical Foundations and Module 4 - Visualizations\
Given the lectures above, please create statistics and visualization on your Data Set to identify good columns for modeling, potential data quality issues and anticipate potential feature transformations necessary.\
Create a jupyter notebook where you document your code and include visualizations as first deliverable. Please also stick to the naming conventions explained in the the process model manual.\
So, the most important reasons / steps are:\
- Identify quality issues (e.g. missing values, wrong measurements, \'85)\
- Assess feature quality \'96 how relevant is a certain measurement (e.g. use correlation matrix)\
- Get an idea on the value distribution of your data using statistical measures and visualizations\
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 \cb3 \outl0\strokewidth0 STEP 2 =Documented Your Work\cf4 \cb3 \
\pard\pardeftab720\sl400\sa400\partightenfactor0
\cf5 \cb6 \outl0\strokewidth0 \strokec5 As the process model is paired with architectural decision guidelines in an iterative fashion one of the deliverables is an architectural decisions document containing the technology mapping between architectural components and concrete technologies. In addition to the mapping, a justification for the decision of the mapping is required so that resources entering the project at a later stage can retrace the thinking threads of current project decision makers.\
\
Please use the template provided below and start filling the gaps in the document. As the whole process model is iterative, it is favored behavior if this document evolves during the creation of the capstone deliverables.\
\pard\pardeftab720\sl400\sa400\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/IBM/coursera/raw/master/coursera_capstone/Lightweight_IBM%20Cloud_Garage_Method_for_Data_Science_ADD_Template.docx"}}{\fldrslt \cf7 \ul \ulc7 \strokec7 Template}}\
Each step (stop) in the process model comes with a set of guidelines. Please make sure you check them out on the link below and also document any decisions you've made (using the guidelines or your experience or both) as comments/documentation in your deliverables (e.g. jupyther notebooks).\cb1 \
\pard\pardeftab720\sl400\sa400\partightenfactor0
\cf5 \cb6 Keeping source and documentation as tight as possible is highly recommended. So please make use of comments in the code directly and in sections above and below the code.\cb1 \
\cb6 And please keep in mind, good software projects have as much documentation in the code as actual code itself.\cb1 \
\cb6 Following the guidelines will lead to decisions and hopefully to some good comments in and above the code so that a follow-up data scientists understand what you've done.\cb1 \
\
\pard\pardeftab720\sl400\sa400\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/IBM/coursera/tree/master/coursera_capstone/guidelines"}}{\fldrslt \cf7 \cb6 \ul \ulc7 \strokec7 https://github.com/IBM/coursera/tree/master/coursera_capstone/guidelines}}\
\pard\pardeftab720\sl380\partightenfactor0
\cf5 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf4 \cb3 \outl0\strokewidth0 \
\cf2 \cb3 STEP 4 = ETL - Extract Transform Load\
\cf4 \cb3 ETL is one of the first things which needs to be done in a data science project. The nature of this task highly depends on the type of data source. Whether it is relational or unstructured, enterprise data or internet data, persistent data or streaming data. This heavily influences the choice of architecture. Therefore, you must document your choice and thinking process in the Architectural Decision Document (ADD).\
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf4 This task involves \'96 as the name implies \'96 accessing the data source, transforming it in a way it can be easily worked with and finally make it available to downstream analytics processes \'96 either real-time streaming or batch ones.\
In case of operational relational data, de-normalization usually needs to take place, for unstructured data, some feature extraction might already be appropriate and for real-time data, windows are usually created.\
Please create an ETL process, document it and save this deliverable according to the naming convention of the process model.\
\cf2 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf8 \cb3 Data Cleansing\cf2 \cb3 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf4 In some process models Data Cleansing is a separate task, it is closely tied to Feature Creation but also draws findings from the Initial Data Exploration task. The actual data transformations are implemented in the Feature Creation asset deliverable; therefore, Data Cleansing is part of the Feature Creation task in this process model.\
While tuning machine learning models, this deliverable asset is touched on a regular basis anyway because features need to be transformed to increase model performance. In such iterations, often issues with data are detected and therefore need to be corrected/addressed here as well.\
The following none exhaustive list gives you some guidelines:\
\'b7 Data types Are data types of columns matching their content? E.g. is age stored as integer and not as string?\
\'b7\'a0
\f1\b Ranges
\f0\b0 \'a0Does the value distribution of values in a column make sense? Use stats (e.g. min, max, mean, standard deviation) and visualizations (e.g. box-plot, histogram) for help\
\'b7 Emptiness Are all values non-null where mandatory? E.g. client IDs\
\'b7 Uniqueness Are duplicates present where undesired? E.g. client IDs\
\'b7 Set memberships Are only allowed values chosen for categorical or ordinal fields? E.g. Female, Male, Unknown\
\'b7 Foreign key set memberships Are only allowed values chosen as field? E.g. ZIP code\
\'b7 Regular expressions Some files need to stick to a pattern expressed by a regular expression. E.g. a lower-case character followed by 6 digits\
\'b7 Cross-field validation Some fields can impact validity of other fields. E.g. a male person can\'92t be pregnant\
Please transform your data set accordingly and add all code to the Feature Creation asset deliverable. Please comply with the naming convention documented in the process model.\
\pard\pardeftab720\sl380\partightenfactor0
\cf9 Feature Engineering\
\
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf4 eature Creation and Feature Engineering is one of the most important tasks in machine learning since it hugely impacts model performance. This also holds for deep learning, although to a lesser extent. Features can be changed or new features can be created from existing ones\
The following none exhaustive list gives you some guidelines for feature transformation:\
\'b7\'a0
\f1\b Imputing
\f0\b0 \'a0Some algorithms are very sensitive to missing values. Therefore, imputing allows for filling of empty fields based on its value distribution\
\'b7\'a0
\f1\b Imputed time-series quantization
\f0\b0 \'a0Time series often contain streams with measurements at different timestamps. Therefore, it is beneficial to quantize measurements to a common \'93heart beat\'94 and impute the corresponding values. This can be done by sampling from the source time series distributions on the respective quantized time steps\
\'b7\'a0
\f1\b Scaling / Normalizing / Centering
\f0\b0 \'a0Some algorithms are very sensitive differences in value ranges for individual fields. Therefore, it is best practice to center data around zero and scale values to a standard deviation of one\
\'b7\'a0
\f1\b Filtering
\f0\b0 \'a0Sometimes imputing values doesn\'92t perform well, therefore deletion of low quality records is a better strategy\
\'b7\'a0
\f1\b Discretizing
\f0\b0 \'a0Continuous fields might confuse the model, e.g. a discrete set of age ranges sometimes performs better than continuous values, especially on smaller amounts of data and with simpler models\
The following none exhaustive list gives you some guidelines for feature creation:\
\'b7\'a0
\f1\b One-hot-encoding
\f0\b0 \'a0Categorical integer features should be transformed into \'93one-hot\'94 vectors. In relational terms this results in addition of additional columns \'96 one columns for each distinct category\
\'b7\'a0
\f1\b Time-to-Frequency transformation
\f0\b0 \'a0Time-series (and sometimes also sequence data) is recorded in the time domain but can easily transformed into the frequency domain e.g. using FFT (Fast Fourier Transformation)\
\'b7\'a0
\f1\b Month-From-Date
\f0\b0 \'a0Creating an additional feature containing the month independent from data captures seasonal aspects. Sometimes further discretization in to quarters helps as well\
\'b7\'a0
\f1\b Aggregate-on-Target
\f0\b0 \'a0Simply aggregating fields the target variable (or even other fields) can improve performance, e.g. count number of data points per ZIP code or take the median of all values by geographical region\
As feature engineering is an art on itself, this list cannot be exhaustive. It\'92s not expected to become an expert in this topic at this point. Most of it you\'92ll learn by practicing data science on real projects and talk to peers which might share their secrets and tricks with you.\
Please transform your data set accordingly and add all code to the Feature Creation asset deliverable. Please comply with the naming convention documented in the process model.\
\pard\pardeftab720\sl380\partightenfactor0
\cf4 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 STEP 6 = Model Definition\
\cf4 Now it\'92s time to start modelling. So, this is where it really depends on your use case and data set how you want to proceed. For example, if you are in an unsupervised context you can choose between an auto-encoder, PCA or clustering. Or if you are in a supervised context you have choice between different state-of-the-art machine learning and deep learning algorithms. But here are some guidelines which are required to follow:\
- Choose, justify and apply a model performance indicator (e.g. F1 score, true positive rate, within cluster sum of squared error, \'85) to assess your model and justify the choice of an algorithm\
- Implement your algorithm in at least one deep learning and at least one non-deep learning algorithm, compare and document model performance\
- Apply at least one additional iteration in the process model involving at least the feature creation task and record impact on model performance (e.g. data normalizing, PCA, \'85)\
Depending on the algorithm class and data set size you might choose specific technologies / frameworks to solve your problem. Please document all your decisions in the ADD (Architectural Decisions Document).\
Once you think you have achieved a descent model performance save the notebook according to the process model\'92s naming convention and proceed to the model training task.\
\cf2 STEP 7 = Model Training\
\cf4 Once your model is defined, it can be trained. This can happen on a single thread or on a parallel framework like Watson Machine Learning or Apache Spark. In the most simple case Model Definition and Model Training is just a couple of LOCs (lines of code) away. In the case of Watson Machine Learning or Apahe Spark models might need to get serialized and transferred to another technology / framework.\
Please specify and justify the technologies used for model definition and training in the ADD.\
Once you think you have achieved a descent model performance save the notebook according to the process model\'92s naming convention and proceed to the model evaluation task.\
\cf2 STEP 8 = Model Evaluation\cf4 \
Model evaluation is a critical task in data science. This is one of the few measures business stakeholders are interested in. Model performance heavily influences business impact of a data science project. Therefore, it is important to take some time apart in an independent task in the process model.\
So how are models evaluated? In supervised machine learning this is relatively straightforward since you can always create a ground truth and compare your results against ground truth.\
So, we are either splitting data into training-, test- and validation-sets to assess model performance on the test set or we use cross validation. This all is explained in the following coursera course https://www.coursera.org/learn/advanced-machine-learning-signal-processing/ Week 2.\
In case we know what data set we can use as ground truth in supervised learning (classification and regression) we need to define a different measure for evaluation than in unsupervised learning (clustering). Since it depends on the type of model we create, the following none exhaustive lists can be used as a starting point for further research:\
Classification:\
\'b7 Confusion Matrix\
\'b7 Accuracy\
\'b7 Precision\
\'b7 Recall\
\'b7 Specificity\
\'b7 True positive rate\
\'b7 True negative rate\
\'b7 False positive rate\
\'b7 False negative rate\
\'b7 F1-score\
\'b7 Gain and Lift\
\'b7 Kolomogorov Smirnov\
\'b7 Area Under ROC\
\'b7 Gini Coefficient\
\'b7 Concordant \'96 Discordant ratio\
\
Regression:\
\'b7 Root Mean Squared Error (RMSE)\
\'b7 Mean Squared Error\
\'b7 Mean Absolute Error (MAE)\
\'b7 R-Squared\
\'b7 Relative Squared Error\
\'b7 Relative Absolute Error\
\'b7 Sum of Differences\
\'b7 ACF plot of residuals\
\'b7 Histogram of residuals\
\'b7 Residual plots against predictors\
\'b7 Residual plots against fitted values\
\
Clustering:\
\'b7 Adjusted Rand index\
\'b7 Mutual Information\
\'b7 Homogeneity completeness\
\'b7 V-measure\
\'b7 Fowlkes-Mallows\
\'b7 Silhouette Coefficient Calinski-Harabaz\'b6\
References:\
\pard\pardeftab720\sl420\sa400\partightenfactor0
{\field{\*\fldinst{HYPERLINK "http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation"}}{\fldrslt \cf10 \ul \ulc10 http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation}}\
Please choose at least one appropriate model performance measure, justify why you\'92ve used it and document how iterative changes in the feature creation task influence it.\
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf2 STEP 9 = Model Deployment And Data Product\
\cf4 Model deployment comes in many shapes. The key to everything is that the business insights that result from the model are made available to stakeholders. This can happen in various ways. At the simplest level a PDF report is generated (e.g. using a jupyter notebook in Watson Studio) and handed over to business stakeholders. Alternatively, the model is encapsulated behind a REST API and made either available to be consumed by a data product or sold internally or externally as a API (e.g. by using IBM Watson Machine Learning or Fabric for DeepLearning).\
Depending on your use case, please choose and implement an appropriate model deployment option and justify your decisions in the ADD.\
The final delivery of most of the data science projects are data products. Depending on who your stake holders are this might include a formal report document, a bunch of charts with captions, a trained and deployable model or a complete application.\
Although not mandatory for this project, you might want to consider implementing (and also showcasing) a data product. Here a incomplete list of technologies you might want to use:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl380\sa200\partightenfactor0
\ls1\ilvl0\cf4 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
NodeRED dashboards\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
AngularJS/D3 web application\cb1 \
\pard\pardeftab720\sl420\sa400\partightenfactor0
\cf4 \cb3 \
\cf2 STEP 10 = Create Final Deliverables\
Create ADD - Architectural Decisions Document\
\cf4 During the curse of the project you\'92ve made several choices which impact the project. Now it\'92s time to do a final pass on the document and make sure everything is in shape. Please spend some time on it to really make sure everything is consistent. Imagine, that your successor needs to continue with your project without being able to speak to you, so this document is the only way to understand why and how things are implemented as they are.\
\cf2 Create a Video Of Final Presentation\
\cf4 Creating your data product is an important skill. But the stakeholders are paying you. If they are happy, you are happy. If you are employed, happy stakeholders justify your head count. If you are working independently, happy clients ensure follow up orders and if you are in research, your stakeholders are the readers of your publications.\
\
So, in this exercise we want to make sure you have sufficient presentation skills. And since digital eminence is one of the key factors of success for data scientists we encourage you to put your presentation publicly on YouTube.\
(If you REALLY don't like to, just upload it as UNLISTED - if you have any concerns, please contact us using the discussion forum)\
\
So here is what you need to do.\
\
1. Create a presentation targeted at stakeholders introducing\
a) the data set\
b) the use case\
c) the solution to the use case (e.g. your report/notebook, deployed model or data product)\
\
2. Create a presentation targeted at your data science peers introducing\
a) your architectural choices\
b) your data quality assessment, data pre-processing and feature engineering\
c) your model performance indicators\
d) your model algorithm\
\
3. Record a 5-10 minute presentation with the following requirements\
a) You should be visible in the video, at a minimum at the introduction and at the end\
b) The presentations from step 1 and 2 should be visible\
c) Your solution to the use case should be demonstrated and recorded during the video\
d) Put this video to your Youtube channel and name it as follows\
IBM Coursera Advanced Data Science Capstone \'96 YOUR NAME\
}